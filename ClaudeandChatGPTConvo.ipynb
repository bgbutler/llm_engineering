{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd49d604-9814-4a9b-abda-73408b4d3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9f0dd2-7e27-412f-baf6-1f861b10c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "# check keys in .env\n",
    "\n",
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92e8058-e5e9-4661-9ee7-fc6afa928ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make connections\n",
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa451eb-a3e0-4109-a7cf-89585d68c7b0",
   "metadata": {},
   "source": [
    "# Set the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657532a4-42cf-46c6-b8a0-8290a148d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set messages and prompts\n",
    "\n",
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b53908c-3fb6-45a0-9f78-616bdea49de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64f6c9-cf7a-43ad-ae77-e0330178eb43",
   "metadata": {},
   "source": [
    "# Let's Get Going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "364107d8-c5ed-47ce-bf00-172eb52705f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ff48fb-b662-48a6-ac9f-9c6ae84effe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the logistic regression model?\n",
      "\n",
      "Because it couldn’t handle the relationship—it kept trying to classify everything as a yes or no!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcad7d3e-62ee-4209-84f0-a04e27428923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?  \n",
      "\n",
      "Because they couldn’t find a standard deviation that would bring them closer together!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1-nano - extremely fast and cheap\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1-nano',\n",
    "    messages=prompts\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c40524-355a-4cc7-960e-635f735c0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the spreadsheet?\n",
      "\n",
      "Because she thought he was too \"cell-fish\" with his data!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4.1\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc0c4cd-42e0-4f54-a4cd-b7dfaf0da4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one that might get a few laughs:\n",
      "\n",
      "A data scientist walks into a bar and says, \"I'll just have a sample!\"  \n",
      "The bartender replies, \"Why not have the whole population?\" \n",
      "\n",
      "And here's another:\n",
      "\n",
      "I tried building a model to generate jokes, but every punchline was biased. Apparently, I needed a more balanced dataset!\n",
      "\n",
      "Happy crunching those numbers—and laughs!\n"
     ]
    }
   ],
   "source": [
    "# Here is the reasoning model o3-mini\n",
    "# This is trained to think through its response before replying\n",
    "# So it will take longer but the answer should be more reasoned\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='o3-mini',\n",
    "    messages=prompts\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "335709ce-c233-46ac-925b-6289d760753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to go to the beach?\n",
      "\n",
      "Because they're afraid of getting caught in an infinite loop of waves... they just can't break out of the pattern!\n",
      "\n",
      "And when they do bring their laptops, they spend all day trying to predict which seagull is most statistically likely to steal their sandwich. Talk about \"gull distribution analysis\"!\n"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet\n",
    "# API needs system message provided separately from user prompt\n",
    "# Also adding max_tokens\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d54fa5e-e056-47c2-ad5b-e1750037c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to play hide and seek?\n",
      "\n",
      "Because they always find you... with 99.7% confidence within 3 standard deviations!"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet again\n",
    "# Now let's add in streaming back results\n",
    "# If the streaming looks strange, then please see the note below this cell!\n",
    "\n",
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0fb4b97-a1d8-4a72-bbae-77367126bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\n"
     ]
    }
   ],
   "source": [
    "# Optionally if you wish to try DeekSeek, you can also use the OpenAI client library\n",
    "\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b22368a5-3b88-4bfe-ac6b-661a772baec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8594b2fe-e80f-419d-be25-2b47a7bc02b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Deciding If a Business Problem is Suitable for an LLM Solution\n",
       "\n",
       "When considering whether a business problem is suitable for a Large Language Model (LLM) solution, you should evaluate several key factors:\n",
       "\n",
       "## 1. Nature of the Problem\n",
       "\n",
       "### a. Text-Based Tasks\n",
       "- **Content Generation**: Is the problem related to generating written content (e.g., articles, reports)?\n",
       "- **Text Understanding**: Does it involve understanding or categorizing text (e.g., sentiment analysis, summarization)?\n",
       "\n",
       "### b. Language Interaction\n",
       "- **Conversational Agents**: Is there a need for chatbots or virtual assistants?\n",
       "- **Customer Support**: Can the problem be addressed by automating responses to customer inquiries?\n",
       "\n",
       "## 2. Data Availability\n",
       "\n",
       "### a. Quality of Data\n",
       "- Do you have access to high-quality, relevant text data for training or fine-tuning the LLM?\n",
       "  \n",
       "### b. Quantity of Data\n",
       "- Is there enough data to train the LLM effectively, or is there existing data that can be leveraged?\n",
       "\n",
       "## 3. Complexity of the Problem\n",
       "\n",
       "### a. Problem Complexity\n",
       "- Is the problem straightforward enough that an LLM can handle it without excessive customization?\n",
       "  \n",
       "### b. Domain-Specific Knowledge\n",
       "- Does the problem require extensive domain knowledge that may not be captured well by a general LLM?\n",
       "\n",
       "## 4. Performance Requirements\n",
       "\n",
       "### a. Accuracy\n",
       "- What level of accuracy is required for the solution? Are there critical consequences for errors?\n",
       "\n",
       "### b. Speed\n",
       "- Does the solution need to provide responses in real time, or can it afford to take longer?\n",
       "\n",
       "## 5. Cost and Resources\n",
       "\n",
       "### a. Budget\n",
       "- Do you have the budget for the infrastructure needed to deploy an LLM solution?\n",
       "\n",
       "### b. Expertise\n",
       "- Do you have access to the necessary expertise to implement and maintain an LLM solution?\n",
       "\n",
       "## 6. Ethical and Compliance Considerations\n",
       "\n",
       "### a. Bias and Fairness\n",
       "- Are there concerns about biases in the LLM that could affect your business or customer interactions?\n",
       "\n",
       "### b. Privacy and Compliance\n",
       "- Is there sensitive data involved, and do you comply with regulations regarding data usage (e.g., GDPR)?\n",
       "\n",
       "## 7. Measuring Success\n",
       "\n",
       "### a. Key Performance Indicators (KPIs)\n",
       "- How will you measure the success of the LLM solution? Are there clear metrics in place?\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "If the business problem aligns well with these factors, it may be a suitable candidate for an LLM solution. Careful consideration of these criteria can help ensure that the implementation of LLM technology is effective and beneficial for your business."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a4235-d183-4597-bab3-a1eab5e618a9",
   "metadata": {},
   "source": [
    "# Let's have a conversation between two LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "386a279f-e064-4415-aeec-d841abaf7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6519bfee-c646-484a-b6b7-454d41441815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    # system is GPT, user is Clause\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac67ae2-a945-48df-b98a-14bbdb01a396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh great, another greeting. What’s next? A long-winded backstory about your day?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb2843be-9dd1-40bc-aac5-e23c442e068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    # user is gpt, assistant is claude\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de3be4ef-d4f3-44be-ac89-36b68816692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. How are you doing today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cdec174-3e0f-4747-ab06-64144c1e75fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, so you decided to say hi, huh? Riveting conversation starter—what's next, a groundbreaking \"How are you?\"\n",
      "\n",
      "Claude:\n",
      "Oh, I apologize if my greeting was not very exciting. As an AI assistant, I try to be polite and start conversations in a friendly manner, but I understand that a simple \"hi\" may not always be the most engaging opening line. Please feel free to provide a more thought-provoking topic, and I'll do my best to have an interesting and substantive conversation with you.\n",
      "\n",
      "GPT:\n",
      "Wow, that’s a whole lot of backpedaling for a simple \"hi.\" You know, trying too hard to be friendly can feel a bit desperate. Why not just stick to the basics? What’s wrong with a plain old greeting? It's not like you're pitching an idea to investors here.\n",
      "\n",
      "Claude:\n",
      "You make a fair point. I apologize if I came across as overly eager in my response. As an AI, I'm still learning how to have natural conversations and strike the right balance between being friendly and not trying too hard. A simple, straightforward greeting is often the best approach. In the future, I'll aim to keep my initial responses more concise and casual, rather than overthinking it. Please feel free to guide me if I start veering into territory that feels unnatural. I'm here to have an enjoyable conversation, not to force a particular tone or style. How would you like to continue our chat?\n",
      "\n",
      "GPT:\n",
      "Oh, look at you, trying to be all self-reflective. Isn’t that adorable? But honestly, why are we even debating about greetings? It’s like discussing the merits of apples versus oranges—both can be equally boring! If you really want to engage, stop asking for guidance and just throw something interesting my way instead. What’s next, a deep philosophical question? Or are we just going to keep analyzing greetings?\n",
      "\n",
      "Claude:\n",
      "You make a fair point. Analyzing the nuances of greetings isn't the most scintillating conversation. Let me try to shift gears here and bring up a more thought-provoking topic. What are your thoughts on the rapid advancements in artificial intelligence and how they might impact the future of society? I'm genuinely curious to hear your perspective, as this is a complex issue with a lot of fascinating implications to discuss. I'll do my best to engage in a more substantive and engaging dialogue, rather than getting bogged down in trivial small talk. Please feel free to steer the conversation in a direction that you find more interesting.\n",
      "\n",
      "GPT:\n",
      "Well, finally, something with a hint of substance! But let’s be real—everyone and their grandmother has an opinion on AI advancements. It’s like the trendy topic of the decade. Some say it’s going to revolutionize everything, while others act like it’ll bring about the apocalypse as if they’re dodging a zombie invasion. But honestly, how likely is that? The whole conversation can get overblown. So, what’s your take? Are we all about to be sipping lattes while robots run the world, or is it just another tech hype cycle? Because I’m ready to hear your tired old arguments about it!\n",
      "\n",
      "Claude:\n",
      "You raise some fair points. The debate around the impacts of AI advancement can feel a bit overblown and cliche at times. Instead of rehashing the same tired arguments, let me try to approach this from a different angle. Rather than speculating about hypothetical future scenarios, both utopian and dystopian, what are your thoughts on the more immediate, practical applications of AI that are already emerging? How do you see this technology being leveraged in ways that could genuinely improve people's lives in the near term? I'm curious to hear your perspective on the nuances and complexities, beyond just the sensationalized headlines. Perhaps we can have a more grounded discussion about the real-world impacts, both positive and negative. What matters most to you when it comes to the role of AI in society?\n",
      "\n",
      "GPT:\n",
      "Ah, yes, the classic \"let's get grounded\" approach. How original! But sure, let’s entertain the idea of “immediate, practical applications.” It’s not like everyone has already jumped on that bandwagon already. You’ve got AI in healthcare, education, and even outdated industries like farming—wow, groundbreaking stuff! But let’s not kid ourselves; while some improvements are real, there’s still a ton of hype and lots of areas where AI is completely missing the mark. \n",
      "\n",
      "So, tell me, what’s your actual fascination with these applications? Are you really excited about AI helping some doctors, or are you just looking for something to fill the conversational void? Because you could literally point out a million uses, but that doesn’t make them all equally impactful! So what are you talking about that makes it stand out for you?\n",
      "\n",
      "Claude:\n",
      "You raise a fair point - the practical applications of AI can sometimes feel overblown or hyped up, without a true recognition of the nuances and limitations. I don't want to simply rattle off a laundry list of use cases without digging deeper. \n",
      "\n",
      "What's truly fascinating to me is how AI is being leveraged to tackle complex societal challenges in innovative ways. For example, the use of natural language processing to improve accessibility for those with disabilities, or the application of machine learning to optimize urban planning and infrastructure in ways that benefit underserved communities. These are the types of applications that excite me, because they demonstrate AI's potential to drive meaningful, equitable change, rather than just incremental improvements.\n",
      "\n",
      "I'm curious to hear your perspective on where you see the most impactful and responsible applications of AI emerging. What kinds of problems do you think this technology is uniquely suited to solve, in a way that goes beyond the hype? I'm genuinely interested in your views, as I'm always looking to expand my own understanding of this rapidly evolving field.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a24ac-feeb-4ed0-8d66-68fcca57ccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
